# [8주차 과제] 4팀 배연욱

---

### Chapter 9. 텍스트를 위한 인공 신경망
#### 09-1 순차 데이터와 순환 신경망

---

**순차 데이터**는 텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터입니다. 대표적인 순차 데이터로는 글, 대화, 일자별 날씨, 일자별 판매 실적 등을 예로 들 수 있습니다.

**순환 신경망**은 순차 데이터에 잘 맞는 인공 신경망의 한 종류입니다. 순차 데이터를 처리하기 위해 고안된 순환층을 1개 이상 사용한 신경망을 순환 신경망이라고 부릅니다.

순환 신경망에서는 종종 순환층을 **셀**이라 부릅니다. 일반적인 인공 신경망과 마찬가지로 하나의 셀은 여러 개의 뉴런으로 구성됩니다.

순환 신경망에서는 셀의 출력을 특별히 **은닉 상태**라고 부릅니다. 은닉 상태는 다음 층으로 전달될 뿐만 아니라 셀이 다음 타임스텝의 데이터를 처리할 때 재사용됩니다.

---

#### 09-2 순환 신경망으로 IMDB 리뷰 분류하기

**말뭉치**는 자연어 처리에서 사용하는 텍스트 데이터의 모음, 즉 훈련 데이터셋을 일컫습니다.

**토큰**은 텍스트에서 공백으로 구분되는 문자열을 말합니다. 종종 소문자로 변환하고 구둣점은 삭제합니다.

**원-핫 인코딩**은 어떤 클래스에 해당하는 원소만 1이고 나머지는 모두 0인 벡터입니다. 정수로 변환된 토큰을 원-핫 인코딩으로 변환하려면 어휘 사전 크기의 벡터가 만들어집니다.

**단어 임베딩**은 정수로 변환된 토큰을 비교적 작은 크기의 실수 밀집 벡터로 변환합니다. 이런 밀집 벡터는 단어 사이의 관계를 표현할 수 있기 때문에 자연어 처리에서 좋은 성능을 발휘합니다.

---

#### 09-3 LSTM과 GRU 셀

**LSTM(Long Short-Term Memory)** 셀은 타임스텝이 긴 데이터를 효과적으로 학습하기 위해 고안된 순환층입니다. 입력 게이트, 삭제 게이트, 출력 게이트 역할을 하는 작은 셀이 포함되어 있습니다.

LSTM 셀은 은닉 상태 외에 셀 상태를 출력합니다. **셀 상태**는 다음 층으로 전달되지 않으며 현재 셀에서만 순환됩니다.

**GRU(Gated Recurrent Unit)** 셀은 LSTM 셀의 간소화 버전으로 생각할 수 있지만 LSTM 셀에 못지않는 성능을 냅니다.