# [6주차 과제] 4팀 배연욱

---

### Chapter 7. 딥러닝을 시작합니다
#### 07-1 인공 신경망

---

**인공 신경망**은 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘입니다. 이름이 신경망 이지만 실제 우리 뇌를 모델링한 것은 아닙니다. 신경망은 기존의 머신러닝 알고리즘으로 다루기 어려웠던 이미지, 음성, 텍스트 분야에서 뛰어난 성능을 발휘하면서 크게 주목받고 있습니다. 인공 신경망 알고리즘을 종종 딥러닝이라고도 부릅니다.

**텐서플로**는 구글이 만든 딥러닝 라이브러리로 매우 인기가 높습니다. CPU와 GPU를 사용해 인공 신경망 모델을 효율적으로 훈련하며 모델 구축과 서비스에 필요한 다양한 도구를 제공합니다. 텐서플로 2.0부터는 신경망 모델을 빠르게 구성할 수 있는 케라스를 핵심 API로 채택하였습니다. 케라스를 사용하면 간단한 모델에서 아주 복잡한 모델까지 손쉽게 만들 수 있습니다.

**밀집층**은 가장 간단한 인공 신경망의 층입니다. 인공 신경망에는 여러 종류의 층이 있습니다. 밀집층에서는 뉴런들이 모두 연결되어 있기 때문에 완전 연결 층이라고도 부릅니다. 특별히 출력층에 밀집층을 사용할 때는 분류하려는 클래스와 동일한 개수의 뉴런을 사용합니다.

**원-핫 인코딩**은 정숫값을 배열에서 해당 정수 위치의 원소만 1이고 나머지는 모두 0으로 변환합니다. 이런 변환이 필요한 이유는 다중 분류에서 출력층에서 만든 확률과 크로스 엔트로피 손실을 계산하기 위해서 입니다. 텐서플로에서는 ‘sparse _ categorical _ entropy’ 손실을 지정하면 이런 변환을 수행할 필요가 없습니다.

---

#### 07-2 심층 신경망

**심층 신경망**은 2개 이상의 층을 포함한 신경망입니다. 종종 다층 인공 신경망, 심층 신경망, 딥 러닝을 같은 의미로 사용합니다.

**렐루 함수**는 이미지 분류 모델의 은닉층에 많이 사용하는 활성화 함수입니다. 시그모이드 함수는 층이 많을수록 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려워집니다. 렐루 함수는 이런 문제가 없으며 계산도 간단합니다.

**옵티마이저**는 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법을 말합니다. 케라스에는 다양한 경사 하강법 알고리즘이 구현되어 있습니다. 대표적으로 SGD, 네스테로프 모멘텀, RMSprop, Adam 등이 있습니다.

---

#### 07-3 신경망 모델 훈련

**드롭아웃**은 은닉층에 있는 뉴런의 출력을 랜덤하게 꺼서 과대적합을 막는 기법입니다. 드롭아웃은 훈련 중에 적용되며 평가나 예측에서는 적용하지 않습니다. 텐서플로는 이를 자동으로 처리합니다.

**콜백**은 케라스 모델을 훈련하는 도중에 어떤 작업을 수행할 수 있도록 도와주는 도구입니다. 대표적으로 최상의 모델을 자동으로 저장해 주거나 검증 점수가 더 이상 향상되지 않으면 일찍 종료할 수 있습니다.

**조기 종료**는 검증 점수가 더 이상 감소하지 않고 상승하여 과대적합이 일어나면 훈련을 계속 진행하지 않고 멈추는 기법입니다. 이렇게 하면 계산 비용과 시간을 절약할 수 있습니다.